<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BedsideKick</title>
    <style>
        body {
            font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Roboto, sans-serif;
            margin: 0;
            padding: 0;
            min-height: 100vh;
            background-color: #f8f0ff;
            display: flex;
            flex-direction: column;
            align-items: center;
            justify-content: center;
            position: relative;
            overflow-x: hidden;
        }
        
        body::after {
            content: '';
            position: fixed;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background: url('drew.png') center center/cover;
            filter: blur(20px);
            opacity: 0.2;
            z-index: -2;
        }
        
        body::after {
            content: '';
            position: fixed;
            top: 0;
            left: 0;
            right: 0;
            bottom: 0;
            background-color: #f8f0ff;
            z-index: -1;
        }

        .container {
            width: 100%;
            max-width: 800px;
            padding: 40px 20px;
            text-align: center;
            position: relative;
            align-items: center;
            justify-content: center;
            z-index: 1;
        }
        
        .header {
            display: flex;
            align-items: center;
            justify-content: center;
            gap: 40px;
            width: 100%;
            margin-bottom: 40px;
            flex-wrap: wrap;
        }
        
        .text-container {
            flex-grow: 0;
            text-align: center;
            max-width: 500px;
            width: 100%;
            padding: 0 20px;
        }
        
        h1#mainTitle {
            font-size: 48px;
            font-weight: 900;
            margin: 0;
            line-height: 1.2;
            color: #000;
            word-wrap: break-word;
            overflow-wrap: break-word;
            hyphens: auto;
            white-space: normal;
        }

        @media (max-width: 768px) {
            h1#mainTitle {
                font-size: 36px;
            }
            
            .header {
                flex-direction: column;
                gap: 20px;
            }
            
            .text-container {
                padding: 0 10px;
            }
        }
        
        .controls {
            margin-top: 30px;
            display: flex;
            gap: 20px;
            align-items: center;
            justify-content: center;
        }
        
        #response {
            margin: 30px auto;
            padding: 24px;
            background-color: transparent;
            border-radius: 16px;
            text-align: center;
            max-width: 600px;
        }
        
        .audio-controls {
            margin: 30px auto;
            width: 100%;
            max-width: 500px;
            text-align: center;
        }
        
        .stress-meter {
            margin: 20px auto;
            padding: 20px;
            background-color: white;
            border-radius: 16px;
            box-shadow: 0 4px 12px rgba(0,0,0,0.1);
            max-width: 400px;
        }
        .avatar-container {
            width: 200px;
            height: 200px;
            flex-shrink: 0;
            border-radius: 50%;
            overflow: hidden;
            border: 12px solid white;
            box-shadow: 0 4px 20px rgba(0,0,0,0.1);
            background: url('drew.png') center center/cover;
            display: flex;
            align-items: center;
            justify-content: center;
            transition: all 0.3s ease-out;
        }
        .avatar-container svg {
            width: 60%;
            height: 60%;
            fill: #666;
        }
        .subtitle {
            font-size: 24px;
            margin-bottom: 30px;
            color: #333;
        }
        .start-button {
            background-color: white;
            color: #000;
            border: none;
            padding: 16px 32px;
            font-size: 20px;
            font-weight: 600;
            border-radius: 12px;
            cursor: pointer;
            transition: all 0.3s ease;
            box-shadow: 0 4px 12px rgba(0,0,0,0.1);
        }
        .start-button:hover {
            transform: translateY(-2px);
            box-shadow: 0 6px 16px rgba(0,0,0,0.15);
        }
        .start-button:active {
            transform: translateY(0);
        }
        .status-container {
            margin-top: 20px;
            display: flex;
            justify-content: center;
            align-items: center;
            gap: 20px;
        }
        #audioPlayer {
            width: 100%;
            margin-top: 20px;
            border-radius: 8px;
        }
        .visualization-container {
            display: flex;
            justify-content: center;
            align-items: center;
            gap: 20px;
            margin-top: 20px;
        }
        #audioLevel {
            position: absolute;
            bottom: 0;
            width: 100%;
            background-color: #4CAF50;
            transition: height 0.1s;
        }
        .stress-level {
            font-size: 18px;
            font-weight: 600;
            margin-bottom: 12px;
            color: #333;
        }
        .stress-bar {
            height: 8px;
            background-color: rgba(0,0,0,0.1);
            border-radius: 4px;
            overflow: hidden;
        }
        .stress-bar-fill {
            height: 100%;
            transition: width 0.3s ease, background-color 0.3s ease;
            border-radius: 4px;
        }
        .response-text {
            font-size: 18px;
            line-height: 1.6;
            color: #333;
            margin-bottom: 20px;
        }
        .typing-text {
            display: inline-block;
            white-space: pre-wrap;
            overflow: hidden;
            border-right: 2px solid transparent;
            animation: blink-caret 0.75s step-end infinite;
            width: fit-content;
        }
        @keyframes blink-caret {
            from, to { border-color: transparent;}
            50% { border-color: #000;}
        }
        @keyframes pulseBorder {
            0% { transform: scale(1); border-width: 12px; }
            50% { transform: scale(1); border-width: 12px; }
            100% { transform: scale(1); border-width: 12px; }
        }
        
        .avatar-speaking {
            border-color: #F1E3FF;
            animation: pulseBorder 1.5s ease-in-out infinite;
        }

        .logo-container {
            position: fixed;
            bottom: 20px;
            right: 20px;
            width: 150px;
            height: auto;
            z-index: 10;
            opacity: 0.9;
            transition: opacity 0.3s ease;
        }

        .logo-container:hover {
            opacity: 1;
        }

        .logo-container img {
            width: 100%;
            height: auto;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <div class="avatar-container">

            </div>
            <div class="text-container">
                <h1 id="mainTitle" style="flex-wrap: wrap;">Hey. How Can I Help you today</h1>
                <div class="controls">
                    <button id="startBtn" class="start-button" onclick="startRecording()">Start Recording</button>

                </div>
            </div>
        </div>

        <div id="response"></div>
        
        <div class="audio-controls">
            <audio id="audioPlayer" controls style="display: none;"></audio>
        </div>
    </div>

    <div class="logo-container">
        <img src="bedsidekick.png" alt="BedsideKick Logo">
    </div>

    <script>
        const ws = new WebSocket(`ws://${window.location.host}`);
        const startBtn = document.getElementById('startBtn');
        const statusDiv = document.getElementById('status');
        const responseDiv = document.getElementById('response');
        const audioPlayer = document.getElementById('audioPlayer');
        
        let mediaRecorder;
        let audioContext;
        let analyser;
        let microphone;
        let silenceTimeout;
        let isRecording = false;
        let recordingChunks = []; // For recording
        let playbackChunks = []; // For playback
        const SILENCE_THRESHOLD = 0.05;
        const WAKE_THRESHOLD = 0.1;
        const MIN_SPEECH_DURATION = 2000;
        const MAX_SILENCE_DURATION = 2000;
        let silenceStart = null;
        let speechStart = null;
        let isSpeaking = false;

        // Create visualizer bars
        const barCount = 100;
        const bars = [];
        for (let i = 0; i < barCount; i++) {
            const bar = document.createElement('div');
            bar.className = 'bar';
            bar.style.left = `${(i / barCount) * 100}%`;
            bars.push(bar);
        }

        function updateVisualizer(dataArray) {
            const step = Math.floor(dataArray.length / barCount);
            for (let i = 0; i < barCount; i++) {
                const value = dataArray[i * step] / 255;
                bars[i].style.height = `${value * 100}%`;
            }
        }

        function checkSilence(dataArray) {
            const average = dataArray.reduce((a, b) => a + b, 0) / dataArray.length;
            const normalizedAverage = average / 255; // Normalize to 0-1 range
            console.log('Audio level:', normalizedAverage.toFixed(4), 'Threshold:', SILENCE_THRESHOLD);
            return normalizedAverage < SILENCE_THRESHOLD;
        }

        async function startRecording() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                
                // Set up audio context and analyser
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                const source = audioContext.createMediaStreamSource(stream);
                analyser = audioContext.createAnalyser();
                analyser.fftSize = 2048;
                source.connect(analyser);
                
                // Store stream for reuse
                window.audioStream = stream;
                
                startNewRecording();
                monitorAudioLevel();
                
                const startBtn = document.getElementById('startBtn');
                startBtn.textContent = 'Stop Recording';
            } catch (error) {
                console.error('Error starting recording:', error);
            }
        }

        function startNewRecording() {
            if (!window.audioStream) return;
            
            // Set up media recorder
            mediaRecorder = new MediaRecorder(window.audioStream);
            recordingChunks = [];
            
            mediaRecorder.ondataavailable = (event) => {
                if (event.data.size > 0) {
                    recordingChunks.push(event.data);
                }
            };
            
            mediaRecorder.onstop = async () => {
                if (recordingChunks.length === 0) {
                    console.log('No audio data recorded');
                    startNewRecording(); // Restart recording
                    return;
                }

                // Only process if we have enough speech duration
                if (speechStart && Date.now() - speechStart >= MIN_SPEECH_DURATION) {
                    console.log('Processing audio chunk...');
                    const audioBlob = new Blob(recordingChunks, { type: 'audio/wav' });
                    const reader = new FileReader();
                    
                    reader.onload = () => {
                        const base64Audio = reader.result.split(',')[1];
                        ws.send(JSON.stringify({
                            type: 'start',
                            audio: base64Audio,
                            format: 'audio/wav'
                        }));
                    };
                    
                    reader.readAsDataURL(audioBlob);
                } else {
                    console.log('Audio clip too short, discarding...');
                }
                
                recordingChunks = [];
                speechStart = null;
                isSpeaking = false;
                
                // Start a new recording session
                startNewRecording();
            };
            
            // Start recording
            mediaRecorder.start();
            isRecording = true;
        }

        function typeText(element, text) {
            element.textContent = '';
            element.className = 'typing-text';
            
            let i = 0;
            function type() {
                if (i < text.length) {
                    if (text.charAt(i) === '<' && text.charAt(i + 1) === 'b' && text.charAt(i + 2) === 'r' && text.charAt(i + 3) === '>') {
                        element.innerHTML += '<br>';
                        i += 4;
                    } else {
                        element.textContent += text.charAt(i);
                        i++;
                    }
                    setTimeout(type, 50);
                }
            }
            type();
        }

        function monitorAudioLevel() {
            if (!isRecording) return;

            const dataArray = new Float32Array(analyser.fftSize);
            analyser.getFloatTimeDomainData(dataArray);
            
            // Calculate RMS value
            let sum = 0;
            for (let i = 0; i < dataArray.length; i++) {
                sum += dataArray[i] * dataArray[i];
            }
            const rms = Math.sqrt(sum / dataArray.length);
            
            // Update audio level visualization
            
            // Check if we're above wake threshold
            if (rms > WAKE_THRESHOLD) {
                if (!isSpeaking) {
                    console.log('Speech detected above wake threshold');
                    speechStart = Date.now();
                    isSpeaking = true;
                    silenceStart = null;
                }
            } 
            // Check if we're below silence threshold
            else if (rms < SILENCE_THRESHOLD) {
                if (isSpeaking) {
                    if (!silenceStart) {
                        silenceStart = Date.now();
                    } else if (Date.now() - silenceStart > MAX_SILENCE_DURATION) {
                        console.log('Silence detected, stopping current recording');
                        if (mediaRecorder && mediaRecorder.state === 'recording') {
                            mediaRecorder.stop();
                        }
                    }
                }
            } else {
                silenceStart = null;
            }
            
            // Continue monitoring
            requestAnimationFrame(monitorAudioLevel);
        }

        function stopRecording() {
            isRecording = false;
            if (mediaRecorder && mediaRecorder.state !== 'inactive') {
                mediaRecorder.stop();
            }
            if (window.audioStream) {
                window.audioStream.getTracks().forEach(track => track.stop());
                window.audioStream = null;
            }
            if (audioContext) {
                audioContext.close();
            }
            recordingChunks = [];
            statusDiv.textContent = 'Stopped';
            statusDiv.className = 'status disconnected';
            const startBtn = document.getElementById('startBtn');
            startBtn.textContent = 'Start Recording';
        }

        ws.onopen = () => {
            statusDiv.textContent = 'Connected';
            statusDiv.className = 'status connected';
            startBtn.disabled = false;
        };

        ws.onmessage = async (event) => {
            try {
                const message = JSON.parse(event.data);
                console.log('Received message:', message);

                if (message.type === 'response') {
                    // Update main title with typing animation
                    const mainTitle = document.getElementById('mainTitle');
                    typeText(mainTitle, message.text);
                    
                    // Display stress level
                    const responseDiv = document.getElementById('response');
                    const stressColor = getStressColor(message.stressLevel);
                    
                    responseDiv.innerHTML = `
                        <div class="stress-meter">
                            <div class="stress-level">Stress Level: ${message.stressLevel}</div>
                            <div class="stress-bar">
                                <div class="stress-bar-fill" style="width: ${message.stressLevel * 20}%; background-color: ${stressColor};"></div>
                            </div>
                        </div>
                    `;
                } else if (message.type === 'audio') {
                    // Handle audio playback
                    const audioData = message.data;
                    const audioBlob = new Blob([Uint8Array.from(atob(audioData), c => c.charCodeAt(0))], { type: 'audio/mp3' });
                    const audioUrl = URL.createObjectURL(audioBlob);
                    
                    const audioPlayer = document.getElementById('audioPlayer');
                    const avatarContainer = document.querySelector('.avatar-container');
                    
                    audioPlayer.src = audioUrl;
                    audioPlayer.onloadedmetadata = () => {
                        console.log('Audio duration:', audioPlayer.duration);
                        avatarContainer.classList.add('avatar-speaking');
                        audioPlayer.play();
                    };
                    audioPlayer.onended = () => {
                        URL.revokeObjectURL(audioUrl);
                        avatarContainer.classList.remove('avatar-speaking');
                    };
                    // Also remove speaking class if audio is paused
                    audioPlayer.onpause = () => {
                        avatarContainer.classList.remove('avatar-speaking');
                    };
                    // Add speaking class back if audio is played
                    audioPlayer.onplay = () => {
                        avatarContainer.classList.add('avatar-speaking');
                    };
                } else if (message.type === 'error') {
                    console.error('Server error:', message.data);
                    responseDiv.textContent += `\nError: ${message.data}`;
                } else {
                    console.log('Unknown message type:', message.type);
                }
            } catch (error) {
                console.error('Error handling WebSocket message:', error);
            }
        };

        function getStressColor(level) {
            const colors = {
                1: '#4CAF50', // Green - Very calm
                2: '#8BC34A', // Light Green - Mostly calm
                3: '#FFC107', // Yellow - Neutral
                4: '#FF9800', // Orange - Stressed
                5: '#F44336'  // Red - Highly stressed
            };
            return colors[level] || colors[3];
        }

        ws.onerror = (error) => {
            console.error('WebSocket error:', error);
        };

        ws.onclose = (event) => {
            console.log('WebSocket closed:', event.code, event.reason);
            statusDiv.textContent = 'Disconnected';
            statusDiv.className = 'status disconnected';
            startBtn.disabled = true;
            stopRecording();
        };

        startBtn.onclick = startRecording;
    </script>
</body>
</html> 