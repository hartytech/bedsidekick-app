<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BedsideKick</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 20px auto;
            padding: 20px;
        }
        .container {
            background-color: white;
            padding: 20px;
            border-radius: 8px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        .controls {
            margin: 20px 0;
            display: flex;
            align-items: center;
            gap: 20px;
        }
        button {
            padding: 10px 20px;
            border: none;
            border-radius: 5px;
            background-color: #4CAF50;
            color: white;
            cursor: pointer;
            transition: background-color 0.3s;
        }
        button:hover {
            background-color: #45a049;
        }
        #status {
            margin: 10px 0;
            padding: 10px;
            border-radius: 4px;
        }
        .connected {
            background-color: #d4edda;
            color: #155724;
        }
        .disconnected {
            background-color: #f8d7da;
            color: #721c24;
        }
        .listening {
            background-color: #fff3cd;
            color: #856404;
        }
        #response {
            margin-top: 20px;
            padding: 15px;
            border-radius: 8px;
            background-color: #fff;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        #audioPlayer {
            width: 100%;
            margin-top: 20px;
        }
        #audioVisualization {
            width: 20px;
            height: 100px;
            background-color: #f0f0f0;
            margin: 10px;
            position: relative;
            border-radius: 5px;
            overflow: hidden;
        }
        #audioLevel {
            position: absolute;
            bottom: 0;
            width: 100%;
            background-color: #4CAF50;
            transition: height 0.1s;
        }
        .wake-threshold-line {
            position: absolute;
            width: 100%;
            height: 2px;
            background-color: #FF9800;
            bottom: 10%;
        }
        .silence-threshold-line {
            position: absolute;
            width: 100%;
            height: 2px;
            background-color: #F44336;
            bottom: 5%;
        }
        .stress-meter {
            margin-top: 20px;
            padding: 15px;
            border-radius: 8px;
            background-color: #f5f5f5;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        .stress-level {
            font-weight: bold;
            margin-bottom: 8px;
            display: block;
        }
        .stress-bar {
            height: 12px;
            margin-top: 8px;
            border-radius: 6px;
            transition: all 0.3s ease;
            background-color: #ddd;
            position: relative;
        }
        .stress-bar-fill {
            height: 100%;
            border-radius: 6px;
            transition: width 0.3s ease, background-color 0.3s ease;
            width: 0%;
        }
        .visualization-container {
            display: flex;
            align-items: center;
            gap: 20px;
        }
        .thresholds {
            font-size: 12px;
            color: #666;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>BedsideKick</h1>
        <div class="controls">
            <button id="startBtn" onclick="startRecording()">Start Listening</button>
        </div>
        <div id="status" class="disconnected">Disconnected</div>
        <div class="visualization-container">
            <div id="audioVisualization">
                <div id="audioLevel"></div>
                <div class="wake-threshold-line"></div>
                <div class="silence-threshold-line"></div>
            </div>
            <div class="thresholds">
                <div>Wake Threshold: 0.1</div>
                <div>Silence Threshold: 0.05</div>
            </div>
        </div>
        <div id="response"></div>
        <audio id="audioPlayer" controls></audio>
    </div>

    <script>
        const ws = new WebSocket(`ws://${window.location.host}`);
        const startBtn = document.getElementById('startBtn');
        const statusDiv = document.getElementById('status');
        const responseDiv = document.getElementById('response');
        const audioPlayer = document.getElementById('audioPlayer');
        
        let mediaRecorder;
        let audioContext;
        let analyser;
        let microphone;
        let silenceTimeout;
        let isRecording = false;
        let recordingChunks = []; // For recording
        let playbackChunks = []; // For playback
        const SILENCE_THRESHOLD = 0.05;
        const WAKE_THRESHOLD = 0.1;
        const MIN_SPEECH_DURATION = 2000;
        const MAX_SILENCE_DURATION = 2000;
        let silenceStart = null;
        let speechStart = null;
        let isSpeaking = false;

        // Create visualizer bars
        const barCount = 100;
        const bars = [];
        for (let i = 0; i < barCount; i++) {
            const bar = document.createElement('div');
            bar.className = 'bar';
            bar.style.left = `${(i / barCount) * 100}%`;
            document.getElementById('audioVisualization').appendChild(bar);
            bars.push(bar);
        }

        function updateVisualizer(dataArray) {
            const step = Math.floor(dataArray.length / barCount);
            for (let i = 0; i < barCount; i++) {
                const value = dataArray[i * step] / 255;
                bars[i].style.height = `${value * 100}%`;
            }
        }

        function checkSilence(dataArray) {
            const average = dataArray.reduce((a, b) => a + b, 0) / dataArray.length;
            const normalizedAverage = average / 255; // Normalize to 0-1 range
            console.log('Audio level:', normalizedAverage.toFixed(4), 'Threshold:', SILENCE_THRESHOLD);
            return normalizedAverage < SILENCE_THRESHOLD;
        }

        async function startRecording() {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                
                // Set up audio context and analyser
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                const source = audioContext.createMediaStreamSource(stream);
                analyser = audioContext.createAnalyser();
                analyser.fftSize = 2048;
                source.connect(analyser);
                
                // Store stream for reuse
                window.audioStream = stream;
                
                startNewRecording();
                monitorAudioLevel();
                
                document.getElementById('startBtn').textContent = 'Stop Recording';
            } catch (error) {
                console.error('Error starting recording:', error);
            }
        }

        function startNewRecording() {
            if (!window.audioStream) return;
            
            // Set up media recorder
            mediaRecorder = new MediaRecorder(window.audioStream);
            recordingChunks = [];
            
            mediaRecorder.ondataavailable = (event) => {
                if (event.data.size > 0) {
                    recordingChunks.push(event.data);
                }
            };
            
            mediaRecorder.onstop = async () => {
                if (recordingChunks.length === 0) {
                    console.log('No audio data recorded');
                    startNewRecording(); // Restart recording
                    return;
                }

                // Only process if we have enough speech duration
                if (speechStart && Date.now() - speechStart >= MIN_SPEECH_DURATION) {
                    console.log('Processing audio chunk...');
                    const audioBlob = new Blob(recordingChunks, { type: 'audio/wav' });
                    const reader = new FileReader();
                    
                    reader.onload = () => {
                        const base64Audio = reader.result.split(',')[1];
                        ws.send(JSON.stringify({
                            type: 'start',
                            audio: base64Audio,
                            format: 'audio/wav'
                        }));
                    };
                    
                    reader.readAsDataURL(audioBlob);
                } else {
                    console.log('Audio clip too short, discarding...');
                }
                
                recordingChunks = [];
                speechStart = null;
                isSpeaking = false;
                
                // Start a new recording session
                startNewRecording();
            };
            
            // Start recording
            mediaRecorder.start();
            isRecording = true;
        }

        function monitorAudioLevel() {
            if (!isRecording) return;

            const dataArray = new Float32Array(analyser.fftSize);
            analyser.getFloatTimeDomainData(dataArray);
            
            // Calculate RMS value
            let sum = 0;
            for (let i = 0; i < dataArray.length; i++) {
                sum += dataArray[i] * dataArray[i];
            }
            const rms = Math.sqrt(sum / dataArray.length);
            
            // Update audio level visualization
            const levelMeter = document.getElementById('audioLevel');
            levelMeter.style.height = `${rms * 100}%`;
            
            // Check if we're above wake threshold
            if (rms > WAKE_THRESHOLD) {
                if (!isSpeaking) {
                    console.log('Speech detected above wake threshold');
                    speechStart = Date.now();
                    isSpeaking = true;
                    silenceStart = null;
                }
            } 
            // Check if we're below silence threshold
            else if (rms < SILENCE_THRESHOLD) {
                if (isSpeaking) {
                    if (!silenceStart) {
                        silenceStart = Date.now();
                    } else if (Date.now() - silenceStart > MAX_SILENCE_DURATION) {
                        console.log('Silence detected, stopping current recording');
                        if (mediaRecorder && mediaRecorder.state === 'recording') {
                            mediaRecorder.stop();
                        }
                    }
                }
            } else {
                silenceStart = null;
            }
            
            // Continue monitoring
            requestAnimationFrame(monitorAudioLevel);
        }

        function stopRecording() {
            isRecording = false;
            if (mediaRecorder && mediaRecorder.state !== 'inactive') {
                mediaRecorder.stop();
            }
            if (window.audioStream) {
                window.audioStream.getTracks().forEach(track => track.stop());
                window.audioStream = null;
            }
            if (audioContext) {
                audioContext.close();
            }
            recordingChunks = [];
            statusDiv.textContent = 'Stopped';
            statusDiv.className = 'status disconnected';
            document.getElementById('startBtn').textContent = 'Start Listening';
        }

        ws.onopen = () => {
            statusDiv.textContent = 'Connected';
            statusDiv.className = 'status connected';
            startBtn.disabled = false;
        };

        ws.onmessage = async (event) => {
            try {
                const message = JSON.parse(event.data);
                console.log('Received message:', message);

                if (message.type === 'response') {
                    // Display text response and stress level
                    const responseDiv = document.getElementById('response');
                    const stressColor = getStressColor(message.stressLevel);
                    
                    responseDiv.innerHTML = `
                        <p>${message.text}</p>
                        <div class="stress-meter">
                            <span class="stress-level">Stress Level: ${message.stressLevel}</span>
                            <div class="stress-bar">
                                <div class="stress-bar-fill" style="width: ${message.stressLevel * 20}%; background-color: ${stressColor};"></div>
                            </div>
                        </div>
                    `;
                } else if (message.type === 'audio') {
                    // Handle audio playback
                    const audioData = message.data;
                    const audioBlob = new Blob([Uint8Array.from(atob(audioData), c => c.charCodeAt(0))], { type: 'audio/mp3' });
                    const audioUrl = URL.createObjectURL(audioBlob);
                    
                    const audioPlayer = document.getElementById('audioPlayer');
                    audioPlayer.src = audioUrl;
                    audioPlayer.onloadedmetadata = () => {
                        console.log('Audio duration:', audioPlayer.duration);
                        audioPlayer.play();
                    };
                    audioPlayer.onended = () => {
                        URL.revokeObjectURL(audioUrl);
                    };
                } else if (message.type === 'error') {
                    console.error('Server error:', message.data);
                    responseDiv.textContent += `\nError: ${message.data}`;
                } else {
                    console.log('Unknown message type:', message.type);
                }
            } catch (error) {
                console.error('Error handling WebSocket message:', error);
            }
        };

        function getStressColor(level) {
            const colors = {
                1: '#4CAF50', // Green - Very calm
                2: '#8BC34A', // Light Green - Mostly calm
                3: '#FFC107', // Yellow - Neutral
                4: '#FF9800', // Orange - Stressed
                5: '#F44336'  // Red - Highly stressed
            };
            return colors[level] || colors[3];
        }

        ws.onerror = (error) => {
            console.error('WebSocket error:', error);
        };

        ws.onclose = (event) => {
            console.log('WebSocket closed:', event.code, event.reason);
            statusDiv.textContent = 'Disconnected';
            statusDiv.className = 'status disconnected';
            startBtn.disabled = true;
            stopRecording();
        };

        startBtn.onclick = startRecording;
    </script>
</body>
</html> 
</html> 